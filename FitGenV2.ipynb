{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9573d9ca-0a8d-4b7a-a086-e62db4cac355",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git add .\n",
    "!git commit -m \"Updated notebook with new results\"\n",
    "!git push origin main\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c932113-8fe6-4ef6-900e-42e64ba5f59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Adem Tounsi\\AppData\\Roaming\\Python\\Python312\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "üöÄ Initializing models and data...\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Ask your question (or 'exit'):  i m 24 yers old 183 cm and weight 90 kg give a starter workout\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìö Top Retrieved Chunks:\n",
      "\n",
      "--- Chunk 1 ---\n",
      "### ELITE SWIMMING WORKOUT_full_text.txt Expands the size of your hands, to work on your pull. Get a size that works for your hand, I wouldn‚Äôt recommend going overboard with the monster sized ones. Buoy: To put in between your legs and to stop kicking, and for rotations. Bread and butter of swim workouts. Chutes: Strap it to your waist and significantly increase the resistance you feel in the water. Must have for sprinters. Med Balls: Like a basketball, but heavy. Provides just the right medicine you need to get your muscles in shape. *All the of the workouts are designed\n",
      "\n",
      "--- Chunk 2 ---\n",
      "### MASTERING SWIMMING_full_text.txt raises your heart rate into an aerobic zone (60 to 70 percent of MHR). After the warm-up, move through the workout from the largest muscle groups (abdominals) to the smaller, more specific ones (arms). Finally, scheduling 10 minutes to relax and stretch your muscles at the conclusion of your session will reduce any soreness you may feel the next day. --- Page 148 Text --- 132 Mastering Swimming Cool Toys for dry-land Training Athletes who do their dry-land training in a gym have the luxury of selecting from a variety of equipment, such as hand weights, full\n",
      "\n",
      "--- Chunk 3 ---\n",
      "### STRENGTH TRAINING FOR FASTER SWIMMING_full_text.txt result of a growth-related posture imbalance in which the spine curves toward the belly. It is a condition that is usually soon outgrown. Children at this stage have an immense amount of energy but limited coordination and very little endurance. The objective of strength training at this stage of development is to build a solid athletic base. Appropriate strength training sessions three to five days a week, for about 15 minutes, should include activities that promote the five areas of general athleticism ‚Äì using the child‚Äôs own resistance only ‚Äì in short periods of\n",
      "\n",
      "üß† Generating answer with LLaMA 3 (Ollama)...\n",
      "\n",
      "üí¨ Answer:\n",
      " Based on the provided context, I'd recommend a starter workout that focuses on building overall athleticism. Since you're 24 years old, 183 cm tall, and weigh 90 kg, here's a starting point:\n",
      "\n",
      "**Warm-up (5 minutes)**\n",
      "\n",
      "* Light swimming to get your heart rate up\n",
      "* Dynamic stretching for your major muscle groups (legs, hips, back, arms, and shoulders)\n",
      "\n",
      "**Strength Training (15-20 minutes)**\n",
      "\n",
      "* Mastering Swimming: Focus on exercises that work multiple muscle groups at once. For example:\n",
      "\t+ Bodyweight squats (10 reps)\n",
      "\t+ Push-ups (10 reps)\n",
      "\t+ Planks (30-second hold)\n",
      "\t+ Lunges (10 reps per leg)\n",
      "\t+\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 29\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# === Main Loop ===\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 29\u001b[0m     query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124müîç Ask your question (or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexit\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m query\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexit\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     31\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py:1262\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1260\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1261\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[1;32m-> 1262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_request(\n\u001b[0;32m   1263\u001b[0m     \u001b[38;5;28mstr\u001b[39m(prompt),\n\u001b[0;32m   1264\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent_ident[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   1265\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_parent(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1266\u001b[0m     password\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1267\u001b[0m )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py:1305\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1302\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1303\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m   1304\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1306\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1307\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Ask your question (or 'exit'):  exit\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "import ollama\n",
    "\n",
    "# === Load everything once ===\n",
    "print(\"üöÄ Initializing models and data...\")\n",
    "\n",
    "# Load FAISS index\n",
    "index = faiss.read_index(\"fitgen_vector_db/fitgen_index.faiss\")\n",
    "\n",
    "# Load chunked text\n",
    "with open(\"fitgen_vector_db/fitgen_chunks.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    chunk_lines = [line.strip() for line in f.read().split(\"\\n\\n\") if line.strip()]\n",
    "\n",
    "# Load SentenceTransformer\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\").to(device)\n",
    "if device == \"cuda\":\n",
    "    model = model.half()  # Use float16 on GPU for faster inference\n",
    "\n",
    "# === Utility: truncate each chunk ===\n",
    "def truncate(text, max_tokens=100):\n",
    "    return ' '.join(text.split()[:max_tokens])\n",
    "\n",
    "# === Main Loop ===\n",
    "while True:\n",
    "    query = input(\"\\nüîç Ask your question (or 'exit'): \").strip()\n",
    "    if query.lower() == 'exit':\n",
    "        break\n",
    "\n",
    "    # Encode query\n",
    "    query_vec = np.array(model.encode([query], convert_to_numpy=True), dtype='float32')\n",
    "\n",
    "    # Search in FAISS\n",
    "    k = 3\n",
    "    _, I = index.search(query_vec, k)\n",
    "\n",
    "    # Get and truncate top chunks\n",
    "    top_chunks = [truncate(chunk_lines[i], 100) for i in I[0]]\n",
    "\n",
    "    print(\"\\nüìö Top Retrieved Chunks:\")\n",
    "    for i, chunk in enumerate(top_chunks, 1):\n",
    "        print(f\"\\n--- Chunk {i} ---\\n{chunk}\")\n",
    "\n",
    "    # Build prompt for RAG\n",
    "    context = \"\\n\\n\".join(top_chunks)\n",
    "    prompt = f\"\"\"Use the following context to answer the user's question concisely and clearly.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {query}\n",
    "Answer:\"\"\"\n",
    "\n",
    "    print(\"\\nüß† Generating answer with LLaMA 3 (Ollama)...\")\n",
    "\n",
    "    try:\n",
    "        response = ollama.chat(\n",
    "            model='llama3',  # Faster quantized model\n",
    "            messages=[\n",
    "                {'role': 'user', 'content': prompt}\n",
    "            ],\n",
    "            options={\n",
    "                'temperature': 0.5,\n",
    "                'num_predict': 150\n",
    "            }\n",
    "        )\n",
    "        answer = response['message']['content'].strip()\n",
    "        print(\"\\nüí¨ Answer:\\n\", answer)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Ollama error: {e}\")\n",
    "        print(\"Ensure Ollama is running and llama3:8b-q4 is pulled with 'ollama run llama3:8b-q4'.\")\n",
    "\n",
    "print(\"üëã Session ended.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d895615e-4cfa-4fdf-b492-89f1a907cbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ[\"TOGETHER_API_KEY\"] = \"fa1509060a01b6917baaa50c6a09c4f63c385044e57153b6402599517b6d135d\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "689d782e-e585-474f-a5e8-cf1bffe43157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Loading FAISS index and chunks...\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Ask your question (or 'exit'):  je veux apprendre les basique de natation \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß† Generating with DeepSeek-V3 from Together.ai...\n",
      "\n",
      "üí¨ Answer:\n",
      " Pour apprendre les bases de la natation, concentrez-vous sur :  \n",
      "\n",
      "1. **Respiration** : Expirez sous l‚Äôeau et inspirez hors de l‚Äôeau.  \n",
      "2. **Flottaison** : Ma√Ætrisez la position horizontale (ventre ou dos).  \n",
      "3. **Mouvements de base** :  \n",
      "   - **Battements de jambes** (crawl, dos crawl√©).  \n",
      "   - **Tractions de bras** (mouvements simples comme ceux du crawl).  \n",
      "4. **Coordination** : Combine respiration, bras et jambes.  \n",
      "\n",
      "Pour des guides d√©taill√©s, consultez des ouvrages comme *De arte natandi\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Ask your question (or 'exit'):  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üëã Done.\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "from together import Together\n",
    "import os\n",
    "\n",
    "# === üîë API Key (make sure it's set in environment) ===\n",
    "# export TOGETHER_API_KEY=your_key_here\n",
    "client = Together()  # Reads from os.environ[\"TOGETHER_API_KEY\"]\n",
    "MODEL_NAME = \"deepseek-ai/DeepSeek-V3\"\n",
    "K = 10\n",
    "MAX_TOKENS = 150\n",
    "CHUNK_TRUNCATE_TOKENS = 100\n",
    "\n",
    "# === üöÄ Load FAISS index and chunks ===\n",
    "print(\"üîÑ Loading FAISS index and chunks...\")\n",
    "index = faiss.read_index(\"fitgen_vector_db/fitgen_index.faiss\")\n",
    "with open(\"fitgen_vector_db/fitgen_chunks.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    chunk_lines = [line.strip() for line in f.read().split(\"\\n\\n\") if line.strip()]\n",
    "\n",
    "# === üî† Load SentenceTransformer for embedding ===\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\").to(device)\n",
    "if device == \"cuda\":\n",
    "    model = model.half()\n",
    "\n",
    "def truncate(text, max_tokens=100):\n",
    "    return ' '.join(text.split()[:max_tokens])\n",
    "\n",
    "# === üß† RAG Loop ===\n",
    "while True:\n",
    "    query = input(\"\\nüîç Ask your question (or 'exit'): \").strip()\n",
    "    if query.lower() == \"exit\":\n",
    "        break\n",
    "\n",
    "    # Encode and search\n",
    "    query_vec = np.array(model.encode([query], convert_to_numpy=True), dtype='float32')\n",
    "    _, I = index.search(query_vec, k=K)\n",
    "    top_chunks = [truncate(chunk_lines[i], CHUNK_TRUNCATE_TOKENS) for i in I[0]]\n",
    "\n",
    "    # Build prompt\n",
    "    context = \"\\n\\n\".join(top_chunks)\n",
    "    prompt = f\"\"\"You are a helpful assistant.\n",
    "\n",
    "Use the following context to answer the user's question concisely.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {query}\n",
    "Answer:\"\"\"\n",
    "\n",
    "    print(\"\\nüß† Generating with DeepSeek-V3 from Together.ai...\")\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=MODEL_NAME,\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=MAX_TOKENS,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        answer = response.choices[0].message.content.strip()\n",
    "        print(\"\\nüí¨ Answer:\\n\", answer)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error from Together API: {e}\")\n",
    "\n",
    "print(\"üëã Done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d09fc977-1b33-4c50-8797-5d9c15054116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Loading FAISS index and chunks...\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Ask your question (or 'exit'):  je veux apprendre les basique de natation \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìö Top Retrieved Chunks (Context for LLM):\n",
      "--- Chunk 1 ---\n",
      "### SWIMMING_full_text.txt HOIH Ol dvou JHL NO\n",
      "--------------------\n",
      "--- Chunk 2 ---\n",
      "### BREAKTHROUGH SWIMMING_full_text.txt into this ancient island nation‚Äôs libri duo, quorum prior regulas ipsius artis, posterior vero perception of swimming.] praxin demonstrationemque continet. London: (s.n.). Bernardi, de Oronzio. 1807. Arte de Nadar Compendiada del [Digby‚Äôs De arte natandi was translated into French que Escribio en Italiano. Madrid: (s.n.). from Latin by Melchisedec Thevenot under the title Frost, J. 1816. Scientific swimming. A series of practical L‚ÄôArt de nager a century later. An interesting bibliogra- illustrations on an original and progressive plan, by which phy of Everard Digby, MA, fellow of St. John‚Äôs college, the art of swimming may be readily\n",
      "--------------------\n",
      "--- Chunk 3 ---\n",
      "### ADAPTED AQUATICS PROGRAMMING_full_text.txt lost in the concepts of appro- the inclusive setting is not the LRE. The LRE should priate placement, continuum of services, inclusion, be synonymous with the placement in which the and LRE. Concentrate on seeking the aquatic setting individual learns best. When you carefully match the that best facilitates learning for the individual. Avoid ability of the participant with an appropriate aquatic favoring one particular philosophy of placement, learning environment, the participant will success- thereby causing a disservice to individuals with dis- fully attain swimming and water safety skills. Natu- abilities. The development of swimming and\n",
      "--------------------\n",
      "--- Chunk 4 ---\n",
      "### BREAKTHROUGH SWIMMING_full_text.txt are confined to hell have to cross the river Styx by swimming. If they cannot swim, how would they cross? Within the next 50 years, two more books of note followed. Historia de gentibus septentrionalibus Romae (History of the Northern People) by Olaus Magnus was published in Rome by Magno Gotho in 1555 and discussed swimming among the other leading customs of northern people. The other book was De arte natandi (The Art of Swimming) by Sir Everard Digby, published in England in 1587 but written in Latin because it was considered vulgar in certain quarters to\n",
      "--------------------\n",
      "--- Chunk 5 ---\n",
      "### BREAKTHROUGH SWIMMING_full_text.txt with ological adaptation to occur, arduous training adequate time for the final taper. must be tempered with adequate rest. The con- cept of tapering is based on this realization, and Typical Questions on Tapering over a period of more than 30 years, it has Here are some typical questions a coach often proved to be one of the most significant contri- encounters during the taper phase of the sea- butions to the progress of competitive swim- son: ming. Tapering was first described in the litera- ture‚Äîand in detail‚Äîby Carlile (1963). Both the How long should each swimmer\n",
      "--------------------\n",
      "--- Chunk 6 ---\n",
      "### Swim Smooth_full_text.txt ‚Äòpaeds pur Bunyeup sauytio asap exqoeug cMry pasate aN] y Funypauiog ‚Äî fF worssag WOKE | POURS |P|RL 8/) PELULIOY Jeuped ¬© yum Aipeays | apes eunanny yoee 0} Gurypeeug Aong yng (f Gunyeup su) op qqissod y | sayaieg Arena Bugytis dn-poey yuan sun [z wpoows pure Buoy‚Äîsuj(, ‚Äîuossag Heo + woo pe Wedd ‚ÄòpS ANON 2b] 04 Bungee pue Bugybis jo eeeocad exp ui apg ogi 426 oy suing Gurejoy Bunyjowos ‚ÄîZ vorssag WDD | SUE Hap eo) sayouu Z‚Äî| saurbay , Spal) crm) YUM azed pool we Buqep pray move funqoeiy 9993 5, +\n",
      "--------------------\n",
      "--- Chunk 7 ---\n",
      "### BREAKTHROUGH SWIMMING_full_text.txt before, the prestigious British Library Catalogue simply states that Thevenot‚Äôs book was ‚Äúadapted‚Äù from Digby‚Äôs De arte natandi. Another point for consideration is that Thevenot‚Äôs book was published four years after his death, and it is more than likely that Thevenot only translated Digby‚Äôs work for his own scholarly satisfaction, without intent to publish it. The latter explanations would appear to be more plausible, particularly as Thevenot was a minor celebrity of his day, a highly respected and distin- guished Oriental scholar, and a founder of the French Academy of Sciences. As librarian of the Royal Library\n",
      "--------------------\n",
      "--- Chunk 8 ---\n",
      "### BREAKTHROUGH SWIMMING_full_text.txt the 1930s.] search‚Äîincluding additions, verifications, re- Wynman, Nicolaus. 1538. Colymbetes, sive de arte natandi visions, and annotations‚Äîconducted by me in dialogus et festivus et iucundus lectu. (Dutch Copy). the records of the Library of Congress; the Brit- Ingolstadt, Bavaria: H. Steiner. ish Library Catalogue; the National Union Cata- [Wynman‚Äôs very early text experienced many reincar- log; the Rare Books Division of the National nations, including three Latin reprints in 1623, 1638, Library of Canada; the Library of Parliament, and 1644, and even an 1889 extract in a German publi- cation titled Heidelberg.] Canada; and the North Carolina\n",
      "--------------------\n",
      "--- Chunk 9 ---\n",
      "### BREAKTHROUGH SWIMMING_full_text.txt gathered out of Master Digbie‚Äôs booke of the Frost, J. 1818. The art of swimming. New York: P.W. Gallaudet. art of swimming (trans.). Translated into English for the Clias, Peter H. 1825. An elementary course of gymnastic better instruction of those who understand not the exercises and a new and complete treatise on the art of Latine tongue. With wooden cuts of persons swim- swimming with the report made to the medical faculty of ming. London: (s.n.). Paris on the subject (4th ed.). London: Sherwood, Gilbert Percey, William. 1658. The compleat swimmer, or The art of and\n",
      "--------------------\n",
      "--- Chunk 10 ---\n",
      "### The Swim Coaching Bible_full_text.txt Ge cc 1.27 74 154 at ccm 1.85 Ec Tt 4 1.28 Te 155 at 34 1.82 Sere ot = 12 7 15 ae ccm 1.82 Sore 1 = 1.85 74 162 a 3 1.82 ere earre 1 1.8 Tz ima oH a5 1.85 TR aor max 145 to) 120 a4 FE 182 cy ott 26S 1.20 The 164 oH ae 1.85 Soe 1 LTFe an 4.7 SEI variabon Ore Summer of anaes bie threshold results Babe Lay (ri!) yp (rs) Time, HFyy 9 Fey 920 Sy, SEI Halong) an ¬´¬© LTR: 11 Oc 3a\n",
      "--------------------\n",
      "\n",
      "üß† Generating with DeepSeek-V3 from Together.ai...\n",
      "\n",
      "üí¨ Answer:\n",
      " Pour apprendre les bases de la natation, concentrez-vous sur ces √©l√©ments essentiels :  \n",
      "\n",
      "1. **Respiration** : Expirez sous l‚Äôeau et inspirez hors de l‚Äôeau.  \n",
      "2. **Flottaison** : Ma√Ætrisez la position horizontale (corps d√©tendu, poumons remplis d‚Äôair).  \n",
      "3. **Mouvements de base** :  \n",
      "   - **Battements de jambes** (crawl, dos crawl√©) : jambes tendues, mouvements souples.  \n",
      "   - **Tractions de bras** (crawl) : bras altern√©s, coude haut.  \n",
      "4. **Coordination** : Harmonisez\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Ask your question (or 'exit'):  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üëã Done.\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "from together import Together\n",
    "import os\n",
    "\n",
    "# === üîë API Key (make sure it's set in environment) ===\n",
    "# export TOGETHER_API_KEY=your_key_here\n",
    "client = Together()  # Reads from os.environ[\"TOGETHER_API_KEY\"]\n",
    "MODEL_NAME = \"deepseek-ai/DeepSeek-V3\"\n",
    "K = 10\n",
    "MAX_TOKENS = 150\n",
    "CHUNK_TRUNCATE_TOKENS = 100\n",
    "\n",
    "# === üöÄ Load FAISS index and chunks ===\n",
    "print(\"üîÑ Loading FAISS index and chunks...\")\n",
    "index = faiss.read_index(\"fitgen_vector_db/fitgen_index.faiss\")\n",
    "with open(\"fitgen_vector_db/fitgen_chunks.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    chunk_lines = [line.strip() for line in f.read().split(\"\\n\\n\") if line.strip()]\n",
    "\n",
    "# === üî† Load SentenceTransformer for embedding ===\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\").to(device)\n",
    "if device == \"cuda\":\n",
    "    model = model.half()\n",
    "\n",
    "def truncate(text, max_tokens=100):\n",
    "    return ' '.join(text.split()[:max_tokens])\n",
    "\n",
    "# === üß† RAG Loop ===\n",
    "while True:\n",
    "    query = input(\"\\nüîç Ask your question (or 'exit'): \").strip()\n",
    "    if query.lower() == \"exit\":\n",
    "        break\n",
    "\n",
    "    # Encode and search\n",
    "    query_vec = np.array(model.encode([query], convert_to_numpy=True), dtype='float32')\n",
    "    _, I = index.search(query_vec, k=K)\n",
    "    top_chunks = [truncate(chunk_lines[i], CHUNK_TRUNCATE_TOKENS) for i in I[0]]\n",
    "\n",
    "    # --- NEW: Print the chunks used ---\n",
    "    print(\"\\nüìö Top Retrieved Chunks (Context for LLM):\")\n",
    "    if not top_chunks:\n",
    "        print(\"    No relevant chunks found.\")\n",
    "    else:\n",
    "        for i, chunk in enumerate(top_chunks):\n",
    "            print(f\"--- Chunk {i+1} ---\")\n",
    "            print(chunk)\n",
    "            print(\"-\" * 20) # Separator for readability\n",
    "    # --- END NEW ---\n",
    "\n",
    "    # Build prompt\n",
    "    context = \"\\n\\n\".join(top_chunks)\n",
    "    prompt = f\"\"\"You are a helpful assistant.\n",
    "\n",
    "Use the following context to answer the user's question concisely.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {query}\n",
    "Answer:\"\"\"\n",
    "\n",
    "    print(\"\\nüß† Generating with DeepSeek-V3 from Together.ai...\")\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=MODEL_NAME,\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=MAX_TOKENS,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        answer = response.choices[0].message.content.strip()\n",
    "        print(\"\\nüí¨ Answer:\\n\", answer)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error from Together API: {e}\")\n",
    "\n",
    "print(\"üëã Done.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
